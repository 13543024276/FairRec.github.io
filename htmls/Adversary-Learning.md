---
layout: subpage
title: Fairness in Recommendation System
description: Adversary Learning (In-Processing)
---

<!-- - [<font color="DarkOrchid">' </font>\|<font color="DarkSalmon"> </font>]() \| <font color="Violet">[ Fairness +  Fairness]</font> \| [<font color="DeepPink">知乎</font>]() -->
- [<font color="DarkOrchid">WWW'22 </font>\|<font color="DarkSalmon"> FairGAN: GANs-based Fairness-aware Learning for Recommendations with Implicit Feedback</font>](https://dl.acm.org/doi/abs/10.1145/3485447.3511958?casa_token=ci1zK1MeljkAAAAA:4f35VBxLz2p0up57OIDjNYwbrQWTaYWjIm5k3gFPpfIJryXu4yrPEf0X23ppAGbf4BlnMsIOfSH90JU) \| <font color="Violet">[Individual Fairness + Item Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/508898118)
- [<font color="DarkOrchid">KDD'22 </font>\|<font color="DarkSalmon"> Comprehensive Fair Meta-learned Recommender System</font>](https://dl.acm.org/doi/10.1145/3534678.3539269) \| <font color="Violet">[Individual Fairness + Group Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/554268676)
- [<font color="DarkOrchid">Arxiv'22 </font>\|<font color="DarkSalmon"> FairRank: Fairness-aware Single-tower Ranking Framework for News Recommendation</font>](https://arxiv.org/abs/2204.00541) \| <font color="Violet">[Individual Fairness + User Fairness]</font>
- [<font color="DarkOrchid">AAAI'21 </font>\|<font color="DarkSalmon"> Fairness-aware News Recommendation with Decomposed Adversarial Learning</font>](https://ojs.aaai.org/index.php/AAAI/article/view/16573) \| <font color="Violet">[Individual Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/437339355)
- [<font color="DarkOrchid">SIGIR'21 </font>\|<font color="DarkSalmon"> Towards Personalized Fairness based on Causal Notion</font>](https://dl.acm.org/doi/abs/10.1145/3404835.3462966?casa_token=IKPz455rovAAAAAA:YkffjU_9A2HfKXmgYBGWIcQnpPqBVhE8z8yzxCnu63rnb2PPFLnEYt9x4N9JSrcl0h6SggYmy4mA7YQ) \| <font color="Violet">[Individual Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/432969760)
- [<font color="DarkOrchid">WWW'21 </font>\|<font color="DarkSalmon"> Learning Fair Representations for Recommendation: A Graph-based Perspective</font>](https://dl.acm.org/doi/abs/10.1145/3442381.3450015?casa_token=JZP89APevqoAAAAA:x4adSwi12IUwGVEcolVAaAoAjRkfPiIwkeHu8QvhHYK9qhHOIUYQsFsv4BTLq9x5qZpXoon6i_GztDs) \| <font color="Violet">[Individual Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/433648567)
- [<font color="DarkOrchid">WSDM'21 </font>\|<font color="DarkSalmon"> Say No to the Discrimination: Learning Fair Graph Neural Networks with Limited Sensitive Attribute Information</font>](https://dl.acm.org/doi/abs/10.1145/3437963.3441752) \| <font color="Violet">[Individual Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/554125217)
- [<font color="DarkOrchid">SIGIR'20 </font>\|<font color="DarkSalmon"> Measuring and Mitigating Item Under-Recommendation Bias in Personalized Ranking Systems</font>](https://dl.acm.org/doi/abs/10.1145/3397271.3401177) \| <font color="Violet">[Group Fairness + Item Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/477799550)
- [<font color="DarkOrchid">WSDM'20 </font>\|<font color="DarkSalmon"> Privacy-Aware Recommendation with Private-Attribute Protection using Adversarial Learning</font>](https://dl.acm.org/doi/abs/10.1145/3336191.3371832?casa_token=T6LMYf-kzXoAAAAA:oPhyhlRNpegcJ4sIF4kGcmQtfeFaZa0oQcWo3TajY3yHimCtGLVWH9GFSy--7bOGUUPFQSoINGEeGXE) \| <font color="Violet">[Individual Fairness + User Fairness]</font>
- [<font color="DarkOrchid">ICML'19 </font>\|<font color="DarkSalmon"> Compositional Fairness Constraints for Graph Embeddings</font>](https://proceedings.mlr.press/v97/bose19a.html) \| <font color="Violet">[Individual Fairness + User Fairness]</font> \| [<font color="DeepPink">知乎</font>](https://zhuanlan.zhihu.com/p/472853603)

# Other Fields
- [<font color="DarkOrchid">ICCV'19 </font>\|<font color="DarkSalmon"> Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations</font>](https://arxiv.org/abs/1811.08489)
- [<font color="DarkOrchid">EMNLP'18 </font>\|<font color="DarkSalmon"> Adversarial Removal of Demographic Attributes from Text Data</font>](https://aclanthology.org/D18-1002/)
- [<font color="DarkOrchid">NAACL'18 </font>\|<font color="DarkSalmon"> KBGAN: Adversarial Learning for Knowledge Graph Embeddings</font>](https://aclanthology.org/N18-1133/)
- [<font color="DarkOrchid">NIPS'17 </font>\|<font color="DarkSalmon"> Controllable invariance through adversarial feature learning</font>](https://dl.acm.org/doi/10.5555/3294771.3294827)
- [<font color="DarkOrchid">FAT'17 </font>\|<font color="DarkSalmon"> Data Decisions and Theoretical Implications when Adversarially Learning Fair Representations</font>](https://arxiv.org/abs/1707.00075)
- [<font color="DarkOrchid">ICLR'15 </font>\|<font color="DarkSalmon"> Censoring Representations with an Adversary</font>](https://arxiv.org/abs/1511.05897)
